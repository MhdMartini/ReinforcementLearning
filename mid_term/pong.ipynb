{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technological-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame as pg\n",
    "from itertools import count, product\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920aba9",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educated-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pong table dimensions\"\"\"\n",
    "WIDTH = HEIGHT = 1\n",
    "\n",
    "\"\"\"pong peddles dimensions\"\"\"\n",
    "P_W = 0.2\n",
    "P_H = 0.02\n",
    "\n",
    "\"\"\"pong peddles y positions\"\"\"\n",
    "Y0 = 0.9\n",
    "Y1 = 0.1\n",
    "\n",
    "\"\"\"ball attributes\"\"\"\n",
    "BALL_R = 0.02\n",
    "BALL_VY = 1\n",
    "BALL_VX = 0\n",
    "\n",
    "\"\"\"state vector indices\"\"\"\n",
    "X0 = 0  # x position of peddle 0\n",
    "X1 = 1  # x position of peddle 1\n",
    "X_B = 2  # x position of ball\n",
    "Y_B = 3  # y position of ball\n",
    "VX_B = 4  # vx of ball\n",
    "VY_B = 5  # vy of ball\n",
    "\n",
    "dt = 0.01\n",
    "\n",
    "\"\"\"pong gui constants\"\"\"\n",
    "SCALE = 500\n",
    "PAD = int(0.05 * WIDTH * SCALE)\n",
    "PG_W, PG_H = WIDTH * SCALE, HEIGHT * SCALE\n",
    "PED_W, PED_H = int(P_W * SCALE), int(P_H * SCALE)\n",
    "\n",
    "FPS = 20\n",
    "BG_COLOR = pg.Color(50, 50, 50)\n",
    "BORDER_COLOR = pg.Color(220, 220, 220)\n",
    "BALL_COLOR = pg.Color(200, 70, 70)\n",
    "PEDDLE_COLOR = pg.Color(240, 240, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f0aad",
   "metadata": {},
   "source": [
    "### Pong Transition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pong_transition(s, a):\n",
    "    \"\"\"\n",
    "    given state and action vectors, return next state vector and reward\n",
    "    state vector is <x_{p0}, x_{p1}, x_{ball}, y_{ball}, v_x_{ball}, v_y_{ball}>\n",
    "    action_vector is <v_x_{p0}, v_x_{p1}}>\n",
    "    next state vector is <x_{p0} + v_x_{p0}dt, x_{p1} + v_x_{p1}dt, x_{ball} + v_x_{ball}dt, y_{ball} + v_y_{ball}dt, v_x_{ball}_{new}, v_y_{ball}_{new}>\n",
    "    \"\"\"\n",
    "\n",
    "    # get the peddles next positions\n",
    "    # if action takes peddle off the screen, effective action (peddle velocity) is 0\n",
    "    s_p = np.copy(s)\n",
    "    p_trans = s[: X_B] + a * dt\n",
    "    a[(p_trans < P_W/2) | (p_trans > WIDTH-P_W/2)] = 0\n",
    "    s_p[: X_B] += a * dt\n",
    "    \n",
    "    r = np.zeros(2)\n",
    "    terminal = False\n",
    "    # if ball touches either peddle, reverse ball y velocity, and add peddle x velocity to ball x velocity\n",
    "    if s[Y_B] - BALL_R <= Y1:\n",
    "        # if ball is as high as the top peddle\n",
    "        if s[X1] - P_W/2 <= s[X_B] <= s[X1] + P_W/2:\n",
    "            # if ball is on top peddle, \n",
    "            # flip y velocity, and add peddle x velocity to ball x velocity\n",
    "            s_p[VY_B] *= -1\n",
    "            s_p[VX_B] += a[1]\n",
    "        else:\n",
    "            r[1] = -1\n",
    "            terminal = True\n",
    "            \n",
    "    elif s[Y_B] + BALL_R >= Y0:\n",
    "        # if ball is as high as the top peddle\n",
    "        if s[X0] - P_W/2 <= s[X_B] <= s[X0] + P_W/2:\n",
    "            # if ball is on top peddle, \n",
    "            # flip y velocity, and add peddle x velocity to ball x velocity\n",
    "            s_p[VY_B] *= -1\n",
    "            s_p[VX_B] += 3 * a[0]\n",
    "        else:\n",
    "            r[0] = -1\n",
    "            terminal = True\n",
    "\n",
    "    # if ball touches sides, reverse ball x velocity\n",
    "    if s[X_B] <= BALL_R or s[X_B] >= 1-BALL_R:\n",
    "        s_p[VX_B] *= -1\n",
    "        \n",
    "    # transition ball according to its velocity\n",
    "    s_p[X_B: VX_B] += s_p[VX_B: ] * dt\n",
    "\n",
    "    return s_p, r, terminal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d98369",
   "metadata": {},
   "source": [
    "### Pong Gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476863c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongGui:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.screen, self.bg = self.init()\n",
    "        \n",
    "    def init(self):\n",
    "        pg.init()  # initialize pygame\n",
    "        screen = pg.display.set_mode((WIDTH * SCALE + 2 * PAD, HEIGHT * SCALE + 2 * PAD))  # set up the screen\n",
    "        pg.display.set_caption(\"Mohamed Martini\")  # add a caption\n",
    "        bg = pg.Surface(screen.get_size())  # get a background surface\n",
    "        bg = bg.convert()\n",
    "        bg.fill(BG_COLOR)\n",
    "        screen.blit(bg, (0, 0))\n",
    "        return screen, bg\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"show the grid array on the screen\"\"\"\n",
    "        pg.display.flip()\n",
    "        pg.display.update()\n",
    "    \n",
    "    def draw_table(self):\n",
    "        pg.draw.rect(self.screen, BORDER_COLOR, (PAD//2, PAD//2, PG_W + PAD, PG_H + PAD), PAD)\n",
    "        pg.draw.line(self.screen, BORDER_COLOR, (0, PAD//2), (PG_W + 2 * PAD - 2, PAD//2), width=PAD)\n",
    "        pg.draw.line(self.screen, BORDER_COLOR, (0, PG_H + 3 * PAD / 2), (PG_W + 2 * PAD - 2, PG_H + 3 * PAD / 2), width=PAD)\n",
    "        \n",
    "        pg.draw.line(self.screen, BORDER_COLOR, (0, int((PG_H + 2 * PAD) / 2)), \n",
    "                     (int(PG_W + 2 * PAD)-5, int((PG_H + 2 * PAD) / 2)), width=5)\n",
    "        \n",
    "    \n",
    "    def draw_state(self, s):\n",
    "        for center_x, center_y in zip(s[X0: X0 + 2], [Y0, Y1]):\n",
    "            center_x = int(center_x * SCALE + PAD)\n",
    "            center_y = int(center_y * SCALE + PAD)\n",
    "            pg.draw.rect(self.screen, PEDDLE_COLOR, \n",
    "                         (center_x - int(PED_W / 2),\n",
    "                         center_y - int(PED_H / 2),\n",
    "                          int(PED_W),\n",
    "                          int(PED_H))\n",
    "                         )\n",
    "        \n",
    "        circle_center = s[X_B: VX_B] * SCALE + PAD\n",
    "        pg.draw.circle(self.screen, BALL_COLOR, \n",
    "                       circle_center.astype(int),\n",
    "                       int(BALL_R * SCALE), \n",
    "                       width=int(BALL_R * SCALE))\n",
    "    \n",
    "    def reset_screen(self):\n",
    "        self.screen.fill(BG_COLOR)\n",
    "        self.draw_table()\n",
    "    \n",
    "    def play(self, theta0=None, theta1=None):\n",
    "        \"\"\"receive a list of positions on the x axis, and plot the movement of the screen\"\"\"\n",
    "        s = get_s0()\n",
    "        if theta0 is None:\n",
    "            theta0 = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "        if theta1 is None:\n",
    "            theta1 = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "        \n",
    "        clock = pg.time.Clock()\n",
    "        run = True\n",
    "        while run:\n",
    "            clock.tick(FPS)\n",
    "            for event in pg.event.get():\n",
    "                if event.type == pg.QUIT:\n",
    "                    run = False\n",
    "            self.reset_screen()\n",
    "            self.draw_table()\n",
    "            self.draw_state(s)\n",
    "            \n",
    "            self.render()\n",
    "            \n",
    "            a0, _ = get_action(s, theta0)\n",
    "            a1 = np.random.choice(range(3))  # get_action(s, theta1)\n",
    "            s, r, terminal = pong_transition(transform(s, direction=0), np.array((A[a0], A[a1])))\n",
    "            s = transform(s)\n",
    "            if terminal:\n",
    "                s = get_s0()\n",
    "        pg.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9093906",
   "metadata": {},
   "source": [
    "### Actor Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6baf2",
   "metadata": {},
   "source": [
    "#### Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e8b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_s(s: np.array):\n",
    "    \"\"\"return x(s) as fourier basis of state\"\"\"\n",
    "    x = np.zeros(NUM_FEATURES)\n",
    "    for i, c in enumerate(product(range(D + 1), repeat=K)):\n",
    "        c = np.array(c)\n",
    "        x[i] = np.cos(np.pi * s.T @ c)\n",
    "    return x\n",
    "\n",
    "def x_sa(s: np.array, a: int):\n",
    "    \"\"\"return x(s, a) as fourier basis of state, shifted according to the action index\"\"\"\n",
    "    x = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "    start = NUM_FEATURES * a\n",
    "    end = start + NUM_FEATURES\n",
    "    x[start: end] = x_s(s)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def h_s(s: np.array, theta: np.array):\n",
    "    \"\"\"return actions' preferences in state s\"\"\"\n",
    "    h = np.zeros(NUM_ACTIONS)\n",
    "    for a in range(NUM_ACTIONS):\n",
    "        h[a] = theta @ x_sa(s, a)\n",
    "    return h\n",
    "\n",
    "def pi_s(s: np.array, theta: np.array):\n",
    "    \"\"\"return policy at state s\"\"\"\n",
    "    h = h_s(s, theta)\n",
    "    exp = np.exp(h - np.max(h))\n",
    "    return exp / np.sum(exp)\n",
    "\n",
    "def v_s(s: np.array, w: np.array):\n",
    "    \"\"\"return the value of a state given the weights vector\"\"\"\n",
    "    return w @ x_s(s)\n",
    "\n",
    "def get_action(s, theta):\n",
    "    \"\"\"return index of action at state s according to weights theta\"\"\"\n",
    "    policy = pi_s(s, theta)\n",
    "    return np.random.choice(range(NUM_ACTIONS), p=policy), policy\n",
    "\n",
    "def get_pi_gradient(s, a, policy):\n",
    "    \"\"\"compute gradient ln pi(a|s, theta), which equals x(s,a) = \\sum_b \\pi(b|s, theta) x(s,b)\"\"\"\n",
    "    x = x_sa(s, a)\n",
    "    summation = 0\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        summation += policy[i] * x_sa(s, i)\n",
    "    return x - summation\n",
    "\n",
    "def get_s0():\n",
    "    s = np.zeros(K)\n",
    "    s[X0: VX_B] = 0.5\n",
    "    s[VX_B] = np.random.uniform(0.45, 0.55)\n",
    "    s[VY_B] =  1\n",
    "    return s\n",
    "\n",
    "def transform(s, direction=1):\n",
    "    dirs = ((0, 1), (-7, 7))\n",
    "    _s = np.copy(s)\n",
    "    _s[VX_B: ] = np.interp(s[VX_B: ], dirs[direction], dirs[1 - direction])\n",
    "    return _s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac9109",
   "metadata": {},
   "source": [
    "#### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea92672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def actor_critic_et(num_episodes):\n",
    "#     gamma = 1\n",
    "#     theta0 = np.zeros(NUM_ACTIONS * NUM_FEATURES)  # theta for each action\n",
    "#     theta1 = np.zeros(NUM_ACTIONS * NUM_FEATURES)  # theta for each action\n",
    "    \n",
    "#     W0 = np.zeros(NUM_FEATURES)  # weights for estimating v_s\n",
    "#     W1 = np.zeros(NUM_FEATURES)\n",
    "    \n",
    "#     lambda_w = 0.8\n",
    "#     lambda_theta = 0.8\n",
    "    \n",
    "#     alpha_w = 1e-3\n",
    "#     alpha_theta = 1e-3\n",
    "    \n",
    "#     steps_per_e = np.zeros(num_episodes)\n",
    "    \n",
    "#     for episode in range(num_episodes):\n",
    "#         # initialize s\n",
    "#         s = np.random.uniform(0.4, 0.6, size=K)\n",
    "#         s0 = np.copy(s)\n",
    "#         s1 = np.copy(s)\n",
    "#         s1[0], s1[1] = s1[1], s1[0]\n",
    "\n",
    "#         # reset z vectors\n",
    "#         z_theta0 = np.zeros_like(theta0)\n",
    "#         z_w0 = np.zeros_like(W0)\n",
    "#         z_theta1 = np.zeros_like(theta1)\n",
    "#         z_w1 = np.zeros_like(W1)\n",
    "\n",
    "#         # reset gamma multiplier\n",
    "#         I = 1\n",
    "        \n",
    "#         score = np.zeros(2)\n",
    "        \n",
    "#         # loop through episode\n",
    "#         for t in count():\n",
    "#             # select action\n",
    "#             a0, policy0 = get_action(s0, theta0)\n",
    "#             a1, policy1 = get_action(s1, theta1)\n",
    "            \n",
    "#             # take action, observe reward and next state\n",
    "#             a = np.array([A[a0], A[a1]])\n",
    "#             trans = transform(s0, start=(0, 1), end=(-1, 1))\n",
    "#             s_p0, r, terminal = pong_transition(trans, a)\n",
    "#             s_p0 = transform(s_p0, start=(-1, 1), end=(0, 1))\n",
    "            \n",
    "#             s_p1 = np.copy(s_p0)\n",
    "#             s_p1[0], s_p1[1] = s_p1[1], s_p1[0]\n",
    "#             score += r\n",
    "            \n",
    "#             # calculate the error (delta) - account for terminal state\n",
    "#             if terminal:\n",
    "#                 v_sp0, v_sp1 = 0, 0\n",
    "#             else:\n",
    "#                 v_sp0, v_sp1 = v_s(s_p0, W0), v_s(s_p1, W1)\n",
    "            \n",
    "#             delta0 = r[0] + gamma * v_sp0  - v_s(s0, W0)\n",
    "#             delta1 = r[1] + gamma * v_sp1  - v_s(s1, W1)\n",
    "            \n",
    "#             # update z_w\n",
    "#             z_w0 = gamma * lambda_w * z_w0 + x_s(s0)\n",
    "#             z_w1 = gamma * lambda_w * z_w1 + x_s(s1)\n",
    "            \n",
    "#             # update z_theta\n",
    "#             gradient0 = get_pi_gradient(s0, a0, policy0)\n",
    "#             z_theta0 = gamma * lambda_theta * z_theta0 + I * gradient0\n",
    "#             gradient1 = get_pi_gradient(s1, a1, policy1)\n",
    "#             z_theta1 = gamma * lambda_theta * z_theta1 + I * gradient1\n",
    "            \n",
    "#             # update w\n",
    "#             W0 += alpha_w * delta0 * z_w0\n",
    "#             W1 += alpha_w * delta1 * z_w1\n",
    "            \n",
    "#             # update theta\n",
    "#             theta0 += alpha_theta * delta0 * z_theta0\n",
    "#             theta1 += alpha_theta * delta1 * z_theta1\n",
    "            \n",
    "#             if terminal:\n",
    "#                 print(episode, t)\n",
    "# #                 print(theta0)\n",
    "#                 break\n",
    "            \n",
    "#             I *= gamma\n",
    "#             s0 = s_p0\n",
    "#             s1 = s_p1\n",
    "        \n",
    "#         steps_per_e[episode] = t\n",
    "            \n",
    "#     return theta0, theta1, steps_per_e\n",
    "\n",
    "def actor_critic_et(num_episodes):\n",
    "    gamma = 0.99\n",
    "    theta0 = np.zeros(NUM_ACTIONS * NUM_FEATURES)  # theta for each action\n",
    "    theta1 = np.zeros(NUM_ACTIONS * NUM_FEATURES)\n",
    "    \n",
    "    W = np.zeros(NUM_FEATURES)  # weights for estimating v_s\n",
    "    \n",
    "    lambda_w = 0.8\n",
    "    lambda_theta = 0.8\n",
    "    \n",
    "    alpha_w = 1e-3\n",
    "    alpha_theta = 1e-4\n",
    "    \n",
    "    steps_per_e = np.zeros(num_episodes)\n",
    "    \n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        # initialize s\n",
    "        s = get_s0()\n",
    "\n",
    "        # reset z vectors\n",
    "        z_theta = np.zeros_like(theta0)\n",
    "        z_w = np.zeros_like(W)\n",
    "\n",
    "        # reset gamma multiplier\n",
    "        I = 1\n",
    "        \n",
    "        score = np.zeros(2)\n",
    "        \n",
    "        # loop through episode\n",
    "        for t in count():\n",
    "            # select action\n",
    "            a0, policy0 = get_action(s, theta0)\n",
    "            a1 = np.random.choice(range(3))\n",
    "            \n",
    "            # take action, observe reward and next state\n",
    "            s_sim = transform(s, direction=0)\n",
    "            a_sim = np.array([A[a0], A[a1]])\n",
    "            s_p_sim, r, terminal = pong_transition(s_sim, a_sim)\n",
    "            s_p = transform(s_p_sim)\n",
    "            score += r\n",
    "            \n",
    "            # calculate the error (delta) - account for terminal state\n",
    "            if terminal:\n",
    "                v_sp = 0\n",
    "            else:\n",
    "                v_sp = v_s(s_p, W)\n",
    "            \n",
    "            delta = r[0] + gamma * v_sp  - v_s(s, W)\n",
    "            \n",
    "            # update z_w\n",
    "            z_w = gamma * lambda_w * z_w + x_s(s)\n",
    "            \n",
    "            # update z_theta\n",
    "            gradient = get_pi_gradient(s, a0, policy0)\n",
    "            z_theta = gamma * lambda_theta * z_theta + I * gradient\n",
    "            \n",
    "            # update w\n",
    "            W += alpha_w * delta * z_w\n",
    "            \n",
    "            # update theta\n",
    "            theta0 += alpha_theta * delta * z_theta\n",
    "            \n",
    "            if terminal or t > 10_000:\n",
    "                break\n",
    "            \n",
    "            I *= gamma\n",
    "            s = s_p\n",
    "        \n",
    "        steps_per_e[episode] = t\n",
    "            \n",
    "    return theta0, theta1, steps_per_e, score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723f8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████▌    | 883/1000 [1:11:23<09:28,  4.86s/it]/tmp/ipykernel_145136/4187323400.py:33: RuntimeWarning: overflow encountered in matmul\n",
      "  return w @ x_s(s)\n",
      "/tmp/ipykernel_145136/3716005586.py:138: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta = r[0] + gamma * v_sp  - v_s(s, W)\n",
      " 88%|█████████████████████████████████▌    | 883/1000 [1:11:24<09:27,  4.85s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_145136/2954257840.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtheta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic_et\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(\"Score:\", score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_145136/3716005586.py\u001b[0m in \u001b[0;36mactor_critic_et\u001b[0;34m(num_episodes)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# select action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0ma0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_145136/4187323400.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(s, theta)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m\"\"\"return index of action at state s according to weights theta\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ACTIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pi_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "BASIS = dict()  # to store the used fourier basis\n",
    "A = np.array([-1, 0, 1])\n",
    "NUM_ACTIONS = 3\n",
    "K = 6\n",
    "D = 3\n",
    "NUM_FEATURES = (D + 1) ** K\n",
    "\n",
    "runs = 1\n",
    "num_episodes = 1000\n",
    "\n",
    "\n",
    "for run in range(runs):\n",
    "    theta0, theta1, steps_per_e, score = actor_critic_et(num_episodes)\n",
    "    np.save(\"theta0\", theta0)\n",
    "\n",
    "# print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9504f73a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_145136/3867038919.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPongGui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# PongGui().play()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theta0' is not defined"
     ]
    }
   ],
   "source": [
    "PongGui().play(theta0, theta1)\n",
    "# PongGui().play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63395581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
