{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technological-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame as pg\n",
    "from itertools import count, product\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920aba9",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educated-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pong table dimensions\"\"\"\n",
    "WIDTH = HEIGHT = 1\n",
    "\n",
    "\"\"\"pong peddles dimensions\"\"\"\n",
    "P_W = 0.2\n",
    "P_H = 0.02\n",
    "\n",
    "\"\"\"pong peddles y positions\"\"\"\n",
    "Y0 = 0.9\n",
    "Y1 = 0.1\n",
    "\n",
    "\"\"\"ball attributes\"\"\"\n",
    "BALL_R = 0.02\n",
    "BALL_VY = 1\n",
    "BALL_VX = 0\n",
    "\n",
    "\"\"\"state vector indices\"\"\"\n",
    "X0 = 0  # x position of peddle 0\n",
    "X1 = 1  # x position of peddle 1\n",
    "X_B = 2  # x position of ball\n",
    "Y_B = 3  # y position of ball\n",
    "VX_B = 4  # vx of ball\n",
    "VY_B = 5  # vy of ball\n",
    "\n",
    "MAX_V = 5\n",
    "dt = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f0aad",
   "metadata": {},
   "source": [
    "### Pong Transition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pong_transition(s, a):\n",
    "    \"\"\"\n",
    "    given state and action vectors, return next state vector and reward\n",
    "    state vector is <x_{p0}, x_{p1}, x_{ball}, y_{ball}, v_x_{ball}, v_y_{ball}>\n",
    "    action_vector is <v_x_{p0}, v_x_{p1}}>\n",
    "    next state vector is <x_{p0} + v_x_{p0}dt, x_{p1} + v_x_{p1}dt, x_{ball} + v_x_{ball}dt, y_{ball} + v_y_{ball}dt, v_x_{ball}_{new}, v_y_{ball}_{new}>\n",
    "    \"\"\"\n",
    "\n",
    "    # get the peddles next positions\n",
    "    # if action takes peddle off the screen, effective action (peddle velocity) is 0\n",
    "#     s[X1] = np.random.uniform(.23, .77)\n",
    "    s_p = np.copy(s)\n",
    "    p_trans = s[: X_B] + a * dt\n",
    "    a[(p_trans < P_W / 2) | (p_trans > WIDTH - P_W / 2)] = 0\n",
    "    s_p[: X_B] += a * dt * MAX_V\n",
    "    \n",
    "    \n",
    "    r = 0\n",
    "    winner = None\n",
    "    terminal = False\n",
    "    # if ball touches either peddle, reverse ball y velocity, and add peddle x velocity to ball x velocity\n",
    "    dy = s[VY_B] * dt\n",
    "    if s[Y_B] + dy <= Y1:\n",
    "        # if ball is as high as the top peddle\n",
    "        if abs(s[X_B] - s[X1]) <= P_W - 2 * BALL_R:\n",
    "            # if ball is on top peddle, \n",
    "            # flip y velocity, and add peddle x velocity to ball x velocity\n",
    "            s_p[VY_B] *= -1\n",
    "            s_p[VX_B] += a[1] * MAX_V\n",
    "        else:\n",
    "            r = 1\n",
    "            winner = 0\n",
    "            terminal = True\n",
    "            \n",
    "    elif s[Y_B] + dy >= Y0:\n",
    "        # if ball is as high as the top peddle\n",
    "        if abs(s[X_B] - s[X0]) <= P_W - 2 * BALL_R:\n",
    "            # if ball is on top peddle, \n",
    "            # flip y velocity, and add peddle x velocity to ball x velocity\n",
    "            s_p[VY_B] *= -1\n",
    "            s_p[VX_B] += a[0] * MAX_V\n",
    "        else:\n",
    "            r = -1\n",
    "            winner = 1\n",
    "            terminal = True\n",
    "\n",
    "    # if ball touches sides, reverse ball x velocity\n",
    "    dx = s[VX_B] * dt\n",
    "    if s[X_B] + dx <= BALL_R or s[X_B] + dx >= 1 - BALL_R:\n",
    "        s_p[VX_B] *= -1\n",
    "        \n",
    "    # transition ball according to its velocity\n",
    "    s_p[X_B: VX_B] += s_p[VX_B: ] * dt\n",
    "\n",
    "\n",
    "    return s_p, r, terminal, winner \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d98369",
   "metadata": {},
   "source": [
    "### Pong Gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476863c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pong gui constants\"\"\"\n",
    "SCALE = 900\n",
    "PAD = int(0.05 * WIDTH * SCALE)\n",
    "PG_W, PG_H = WIDTH * SCALE, HEIGHT * SCALE\n",
    "PED_W, PED_H = int(P_W * SCALE), int(P_H * SCALE)\n",
    "PED_W2, PED_H2 = int(PED_W / 2), int(PED_H / 2)\n",
    "\n",
    "\n",
    "PAD_HF = PAD // 2\n",
    "PG_W_T = PG_W + 2 * PAD\n",
    "PG_H_T = PG_H + 2 * PAD\n",
    "PG_H_32 = PG_H + 3 * PAD / 2\n",
    "PG_W_32 = PG_W + 3 * PAD / 2\n",
    "PG_H_T_HF = int((PG_H_T) / 2)\n",
    "\n",
    "\n",
    "FPS = 20\n",
    "BG_COLOR = pg.Color(50, 50, 50)\n",
    "BORDER_COLOR = pg.Color(220, 220, 220)\n",
    "BALL_COLOR = pg.Color(200, 70, 70)\n",
    "PEDDLE_COLOR = pg.Color(240, 240, 240)\n",
    "\n",
    "class PongGui:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.screen, self.bg = self.init()\n",
    "        \n",
    "    def init(self):\n",
    "        pg.init()  # initialize pygame\n",
    "        screen = pg.display.set_mode((PG_W_T, PG_H_T))  # set up the screen\n",
    "        pg.display.set_caption(\"Mohamed Martini\")  # add a caption\n",
    "        bg = pg.Surface(screen.get_size())  # get a background surface\n",
    "        bg = bg.convert()\n",
    "        bg.fill(BG_COLOR)\n",
    "        screen.blit(bg, (0, 0))\n",
    "        return screen, bg\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"show the grid array on the screen\"\"\"\n",
    "        pg.display.flip()\n",
    "        pg.display.update()\n",
    "    \n",
    "    def draw_table(self):\n",
    "        pg.draw.rect(self.screen, BORDER_COLOR, (PAD_HF, PAD_HF, PG_W + PAD, PG_H + PAD), PAD)\n",
    "        pg.draw.line(self.screen, BORDER_COLOR, (0, PG_H_T_HF), \n",
    "                     (PG_W_T, PG_H_T_HF), width=5)\n",
    "        \n",
    "    \n",
    "    def draw_state(self, s):\n",
    "        for center_x, center_y in zip(s[X0: X0 + 2], [Y0, Y1]):\n",
    "            center_x = int(center_x * SCALE + PAD)\n",
    "            center_y = int(center_y * SCALE + PAD)\n",
    "            pg.draw.rect(self.screen, PEDDLE_COLOR, \n",
    "                         (center_x - PED_W2, \n",
    "                          center_y - PED_H2,\n",
    "                          PED_W,\n",
    "                          PED_H)\n",
    "                         )\n",
    "        \n",
    "        circle_center = s[X_B: VX_B] * SCALE + PAD\n",
    "        pg.draw.circle(self.screen, BALL_COLOR, \n",
    "                       circle_center.astype(int),\n",
    "                       int(BALL_R * SCALE), \n",
    "                       width=int(BALL_R * SCALE))\n",
    "    \n",
    "    def reset_screen(self):\n",
    "        self.screen.fill(BG_COLOR)\n",
    "        self.draw_table()\n",
    "    \n",
    "    def play(self, theta0=None, theta1=None):\n",
    "        \"\"\"receive a list of positions on the x axis, and plot the movement of the screen\"\"\"\n",
    "        s = get_s0()\n",
    "        if theta0 is None:\n",
    "            theta0 = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "        if theta1 is None:\n",
    "            theta1 = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        clock = pg.time.Clock()\n",
    "        run = True\n",
    "        while run:\n",
    "            clock.tick(FPS)\n",
    "            for event in pg.event.get():\n",
    "                if event.type == pg.QUIT:\n",
    "                    run = False\n",
    "            self.reset_screen()\n",
    "            self.draw_table()\n",
    "            self.draw_state(s)\n",
    "\n",
    "            a0, _ = get_action(s[:-2], theta0)\n",
    "            a1 = np.random.choice(range(3))  # get_action(s, theta1)\n",
    "            sp, r, terminal, winner = pong_transition(s, np.array((A[a0], A[a1])))\n",
    "            s = sp\n",
    "            score = score + 1 if winner == 0 else score - 1 if winner == 1 else score \n",
    "            \n",
    "            # print score\n",
    "            myFont = pg.font.SysFont(\"Times New Roman\", 32)\n",
    "            score_disp = myFont.render(str(int(score)), 1, BALL_COLOR)\n",
    "            self.screen.blit(score_disp, (PAD, PAD))\n",
    "\n",
    "            self.render()\n",
    "            \n",
    "            if terminal:\n",
    "                s = get_s0()\n",
    "        pg.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9093906",
   "metadata": {},
   "source": [
    "### Actor Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6baf2",
   "metadata": {},
   "source": [
    "#### Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e8b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_s(s: np.array):\n",
    "    \"\"\"return x(s) as fourier basis of state\"\"\"\n",
    "    x = np.zeros(NUM_FEATURES)\n",
    "    for i, c in enumerate(product(range(D + 1), repeat=K)):\n",
    "        c = np.array(c)\n",
    "        x[i] = np.cos(np.pi * s.T @ c)\n",
    "    return x\n",
    "\n",
    "\n",
    "def x_sa(s: np.array, a: int):\n",
    "    \"\"\"return x(s, a) as fourier basis of state, shifted according to the action index\"\"\"\n",
    "    x = np.zeros(NUM_FEATURES * NUM_ACTIONS)\n",
    "    start = NUM_FEATURES * a\n",
    "    end = start + NUM_FEATURES\n",
    "    x[start: end] = x_s(s)\n",
    "    return x\n",
    "\n",
    "\n",
    "def h_s(s: np.array, theta: np.array):\n",
    "    \"\"\"return actions' preferences in state s\"\"\"\n",
    "    h = np.zeros(NUM_ACTIONS)\n",
    "    for a in range(NUM_ACTIONS):\n",
    "        h[a] = theta @ x_sa(s, a)\n",
    "    return h\n",
    "\n",
    "\n",
    "def pi_s(s: np.array, theta: np.array):\n",
    "    \"\"\"return policy at state s\"\"\"\n",
    "    h = h_s(s, theta)\n",
    "    exp = np.exp(h - np.max(h))\n",
    "    return exp / np.sum(exp)\n",
    "\n",
    "\n",
    "def v_s(s: np.array, w: np.array):\n",
    "    \"\"\"return the value of a state given the weights vector\"\"\"\n",
    "    return w @ x_s(s)\n",
    "\n",
    "\n",
    "def get_action(s, theta):\n",
    "    \"\"\"return index of action at state s according to weights theta\"\"\"\n",
    "    policy = pi_s(s, theta)\n",
    "    return np.random.choice(range(NUM_ACTIONS), p=policy), policy\n",
    "\n",
    "\n",
    "def get_pi_gradient(s, a, policy):\n",
    "    \"\"\"compute gradient ln pi(a|s, theta), which equals x(s,a) = \\sum_b \\pi(b|s, theta) x(s,b)\"\"\"\n",
    "    x = x_sa(s, a)\n",
    "    summation = 0\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        summation += policy[i] * x_sa(s, i)\n",
    "    return x - summation\n",
    "\n",
    "\n",
    "def get_s0():\n",
    "    s = np.zeros(K+2)\n",
    "    s[X0: VX_B] = 0.5\n",
    "    direction = np.random.choice((-1, 1))\n",
    "    s[VX_B] = direction * 0.35 * MAX_V #np.random.uniform(0.45, 0.55)\n",
    "    s[VY_B] =  direction * 0.65 * MAX_V\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac9109",
   "metadata": {},
   "source": [
    "#### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea92672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_critic_et(theta0, theta1, num_episodes):\n",
    "    gamma = 0.99\n",
    "    \n",
    "    W = np.zeros(NUM_FEATURES)  # weights for estimating v_s\n",
    "    \n",
    "    lambda_w = 0.5\n",
    "    lambda_theta = 0.5\n",
    "    \n",
    "    alpha_w = 1e-4\n",
    "    alpha_theta = 1e-4\n",
    "    \n",
    "    steps_per_e = np.zeros(num_episodes)\n",
    "    \n",
    "    winners = 0\n",
    "    improvement = []\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        # initialize s\n",
    "        s = get_s0()\n",
    "\n",
    "        # reset z vectors\n",
    "        z_theta = np.zeros_like(theta0)\n",
    "        z_w = np.zeros_like(W)\n",
    "\n",
    "        # reset gamma multiplier\n",
    "        I = 1\n",
    "        \n",
    "        \n",
    "        # loop through episode\n",
    "        for t in count():\n",
    "            # select action\n",
    "            a0, policy0 = get_action(s[:-2], theta0)\n",
    "            if t == 1 and not episode % 100:\n",
    "                print(f\"{s[X_B] > 0.5} Initial Policy\", policy0)\n",
    "            a1 = np.random.choice(NUM_ACTIONS)\n",
    "            \n",
    "            # take action, observe reward and next state\n",
    "            a = np.array([A[a0], A[a1]])\n",
    "            s_p, r, terminal, winner = pong_transition(s, a)\n",
    "            \n",
    "            # calculate the error (delta) - account for terminal state\n",
    "            if terminal:\n",
    "                v_sp = 0\n",
    "            else:\n",
    "                v_sp = v_s(s_p[:-2], W)\n",
    "            \n",
    "            delta = r + gamma * v_sp  - v_s(s[:-2], W)\n",
    "            \n",
    "            # update z_w\n",
    "            z_w = gamma * lambda_w * z_w + x_s(s[:-2])\n",
    "            \n",
    "            # update z_theta\n",
    "            gradient = get_pi_gradient(s[:-2], a0, policy0)\n",
    "            z_theta = gamma * lambda_theta * z_theta + I * gradient\n",
    "            \n",
    "            # update w\n",
    "            W += alpha_w * delta * z_w\n",
    "            \n",
    "            # update theta\n",
    "            theta0 += alpha_theta * delta * z_theta\n",
    "#             if not t % 100:\n",
    "#                 print(policy0)\n",
    "            \n",
    "            if terminal or t > 1_000:\n",
    "                break\n",
    "            \n",
    "            I *= gamma\n",
    "            s = s_p\n",
    "        \n",
    "        steps_per_e[episode] = t\n",
    "        winners += winner\n",
    "        chunck = 500\n",
    "        if not episode % chunck:\n",
    "            print(episode)\n",
    "            print()\n",
    "            improvement.append(winners / chunck)\n",
    "            winners = 0\n",
    "            \n",
    "    return theta0, theta1, steps_per_e, improvement\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723f8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Weights!\n"
     ]
    }
   ],
   "source": [
    "A = np.array([-1, 0, 1])\n",
    "NUM_ACTIONS = 3\n",
    "K = 4\n",
    "D = 2\n",
    "NUM_FEATURES = (D + 1) ** K\n",
    "\n",
    "runs = 100\n",
    "num_episodes = 100_000\n",
    "# scores = np.zeros((2, num_episodes))\n",
    "\n",
    "filename = \"theta0_69\"\n",
    "base_name, idx = filename.split(\"_\")\n",
    "try:\n",
    "    theta0 = np.load(f\"{filename}.npy\")\n",
    "    theta1 = np.zeros_like(theta0)\n",
    "    print(\"Imported Weights!\")\n",
    "except:\n",
    "    print(\"No old weights were found. Creating new weights\")\n",
    "    theta0 = np.zeros(NUM_ACTIONS * NUM_FEATURES)  # theta for each action\n",
    "    theta1 = np.zeros(NUM_ACTIONS * NUM_FEATURES)\n",
    "\n",
    "# for run in range(1, runs + 1):\n",
    "#     theta0, theta1, steps_per_e, _ = actor_critic_et(theta0, theta1, num_episodes // runs)\n",
    "#     np.save(f\"{base_name}_{run + int(idx)}\", theta0)\n",
    "#     print(\"Saved Weights!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9504f73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PongGui().play(theta0, theta1)\n",
    "# PongGui().play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-counter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
